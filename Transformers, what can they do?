# Transformers, what can they do?
In this section, we will look at what Transformer models can do and use our first tool from the **ðŸ¤— Transformers** library: the `pipeline()` function.

Transformers are everywhere!  
Before diving into how Transformer models work under the hood, letâ€™s look at a few examples of how they can be used to solve some interesting NLP problems.

# Working with pipelines

The most basic object in the ðŸ¤— Transformers library is the `pipeline()` function.  
It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:

Some of the currently available pipelines are:
- feature-extraction
- fill-mask
- ner (named entity recognition)
- question-answering
- sentiment-analysis
- summarization
- text-generation
- translation
- zero-shot-classification


```python
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a short HuggingFace course my whole life.")
```  
We can even pass several sentences!
```python
classifier(["I've been waiting for a short HuggingFace course my whole life.", "I hate this so much"])
```

By default, this pipeline selects a particular pretrained model that has been fine-tuned for sentiment analysis in English. The model is downloaded and cached when you create the classifier object. If you rerun the command, the cached model will be used instead and there is no need to download the model again.

There are three main steps involved when you pass some text to a pipeline:
- The text is preprocessed into a format the model can understand.
- The preprocessed inputs are passed to the model.
- The predictions of the model are post-processed, so you can make sense of them.

