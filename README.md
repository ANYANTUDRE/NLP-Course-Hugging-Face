# NLP-Course-Hugging-Face
This course will teach you about **Natural Language Processing (NLP)** using libraries from the **Hugging Face ðŸ¤—** ecosystem :
- ðŸ¤— Transformers, 
- ðŸ¤— Datasets,
- ðŸ¤— Tokenizers, and
- ðŸ¤— Accelerate â€” as well as the Hugging Face Hub. 

# Introduction 
Before jumping into Transformer models, letâ€™s do a quick overview of what Natural Language Processing is and why we care about it.


# What is NLP?
NLP is a field of linguistics and Machine Learning focused on understanding everything related to human language.   
Common NLP tasks:
- **Classifying sentences and words:** sentiment analysis, email spam detection, grammatical components and named entities identification...
- **Generating text content:** text auto-generation, filling masked words...
- **Extracting an answer from a text:** questions-answers.
- **Generating a new sentence from an input text:** translation, summurization...
  
NLP also tackles complex challenges in **speech recognition** and **computer vision** (audio transcription, image description).

# Why is it challenging?
Computers donâ€™t process information in the same way as humans. Humans can easily understand a sentence meaning or determine how similar two sentences are. For machine learning (ML) models, such tasks are more difficult. The text needs to be processed in a way that enables the model to learn from it. And because language is complex, we need to think carefully about how this processing must be done.
There has been a lot of research done on how to represent text, and we will look at some methods in the next chapter.
